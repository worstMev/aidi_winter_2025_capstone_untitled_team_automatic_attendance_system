{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import cv2\n",
    "import numpy as np\n",
    "from deepface import DeepFace\n",
    "import io\n",
    "import time\n",
    "from mss import mss\n",
    "from datetime import date\n",
    "\n",
    "## Create the client connector to S3 \n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='AKIATG6MGZ27MEZI7EM3',\n",
    "    aws_secret_access_key='NjwfpnIGoKqZYNneFLd6MxRc9QMc15w8YXi5jD3a',\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# Create a session with your AWS access keys and region\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id='AKIATG6MGZ27MEZI7EM3',\n",
    "    aws_secret_access_key='NjwfpnIGoKqZYNneFLd6MxRc9QMc15w8YXi5jD3a',\n",
    "    region_name='us-east-2'  # Change to your desired region\n",
    ")\n",
    "\n",
    "# Create a client for Secrets Manager (or any other service)\n",
    "client = session.client('secretsmanager')\n",
    "\n",
    "\n",
    "bucket_n = \"face-rec-database\"\n",
    "\n",
    "prefix = \"test_data_set/\"\n",
    "\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=bucket_n, Prefix=prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import snowflake.connector as sc\n",
    "\n",
    "\n",
    "## function to get the snowflake private key from aws secret manager\n",
    "def get_secret():\n",
    "    secret_name = \"snowflake/face_rec/rsa_private_key\"\n",
    "    region_name = \"us-east-2\"\n",
    "\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    return secret\n",
    "\n",
    "\n",
    "\n",
    "## funct to convert the key to appropiate format accepte by snowflake connector \n",
    "def load_private_key(pem_str, key_password=None):\n",
    "    \"\"\"\n",
    "    Load a PKCS8 formatted private key from a PEM string.\n",
    "    key_password should be a string if the key is encrypted, otherwise None.\n",
    "    \"\"\"\n",
    "    private_key = serialization.load_pem_private_key(\n",
    "        pem_str.encode(\"utf-8\"),\n",
    "        password=key_password.encode(\"utf-8\") if key_password else None,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "    return private_key\n",
    "\n",
    "# Retrieve the private key string from AWS Secrets Manager.\n",
    "pem_private_key = get_secret()\n",
    "\n",
    "# If your key is not encrypted, key_password is None.\n",
    "key_password = None  # Set this if your private key is password-protected\n",
    "\n",
    "# Load the private key into a cryptography object.\n",
    "private_key = load_private_key(pem_private_key, key_password=key_password)\n",
    "\n",
    "# Snowflake connection parameters using key-pair authentication.\n",
    "conn_params = {\n",
    "    'account': 'TIMCEXC-MYB81917',\n",
    "    'user': 'face_rec_service',\n",
    "    'private_key': private_key,\n",
    "    'warehouse': 'COMPUTE_WH',\n",
    "    'database': 'RECOG_DB',\n",
    "    'schema': 'ATTEND'\n",
    "}\n",
    "\n",
    "# Connect to Snowflake.\n",
    "ctx = sc.connect(**conn_params)\n",
    "cs = ctx.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query.\n",
    "cs.execute(\"SELECT *  FROM RECOG_DB.ATTEND.institution\")\n",
    "print(cs.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = []\n",
    "\n",
    "# List objects in the S3 bucket with the specified prefix\n",
    "response = s3.list_objects_v2(Bucket=bucket_n, Prefix=prefix)\n",
    "\n",
    "for obj in response.get(\"Contents\", []):\n",
    "    key = obj[\"Key\"]\n",
    "    if not key.endswith((\".jpg\", \".jpeg\", \".png\",\"JPG\")):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Retrieve the image from S3\n",
    "        s3_response = s3.get_object(Bucket=bucket_n, Key=key)\n",
    "        img_bytes = s3_response[\"Body\"].read()\n",
    "\n",
    "        # Convert the byte stream to a NumPy array and then decode to an image\n",
    "        np_arr = np.frombuffer(img_bytes, np.uint8)\n",
    "        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Pass the image directly to DeepFace\n",
    "        objs = DeepFace.represent(img_path=img, model_name=\"Facenet\", detector_backend= 'retinaface')\n",
    "        embedding = objs[0][\"embedding\"]\n",
    "        instances.append((key, embedding))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {key}: {e}\")\n",
    "\n",
    "# Now, instances contains tuples of (s3_object_key, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## incremental de instances \n",
    "\n",
    "\n",
    "preloaded_imgs =  cs.execute (\"\"\"select  img_name\n",
    "from RECOG_DB.ATTEND.embeddings_test\n",
    "order by ID\"\"\").fetchall()\n",
    "\n",
    "\n",
    "### this list contains all images that are already on the embbedings \n",
    "preloaded_img_list  = [row[0] for row in preloaded_imgs ]\n",
    "\n",
    "\n",
    "print(f\"This is the embedings list before. \\n {preloaded_img_list}\")\n",
    "\n",
    "\n",
    "## initialize an empty list that will containg all new images embeddings \n",
    "instances = []\n",
    "\n",
    "# List objects in the S3 bucket with the specified prefix\n",
    "response = s3.list_objects_v2(Bucket=bucket_n, Prefix=prefix)\n",
    "count = 0 \n",
    "\n",
    "## for loop that will create embeding for all new images in the s3 bucket\n",
    "for obj in response.get(\"Contents\", []):\n",
    "    key = obj[\"Key\"]\n",
    "\n",
    "    ## if image title end in a img format it will continue \n",
    "    if not key.endswith((\".jpg\", \".jpeg\", \".png\",\"JPG\")):\n",
    "        continue\n",
    "    ## if image title is already contained in the embbegings table itll be ignored\n",
    "    elif key in preloaded_img_list:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Retrieve the image from S3\n",
    "        s3_response = s3.get_object(Bucket=bucket_n, Key=key)\n",
    "        img_bytes = s3_response[\"Body\"].read()\n",
    "\n",
    "        # Convert the byte stream to a NumPy array and then decode to an image\n",
    "        np_arr = np.frombuffer(img_bytes, np.uint8)\n",
    "        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "        # Pass the image directly to DeepFace\n",
    "        objs = DeepFace.represent(img_path=img, model_name=\"Facenet\", anti_spoofing= True)\n",
    "        embedding = objs[0][\"embedding\"]\n",
    "        instances.append((key, embedding))\n",
    "        count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {key}: {e}\")\n",
    "\n",
    "\n",
    "print(f\"this is the number of images embbeded {count}\")\n",
    "\n",
    "\n",
    "## insert the new embeddings in the snowflake table \n",
    "\n",
    "for  img_path, embedding in instances:\n",
    "    # Join embedding values into a comma-separated string\n",
    "    vec = str(embedding)\n",
    "    statement = f\"\"\"\n",
    "        INSERT INTO RECOG_DB.ATTEND.embeddings_test (img_name, embedding)\n",
    "            SELECT '{img_path}', {vec}::VECTOR(FLOAT,128)\n",
    "        \"\"\"\n",
    "    cs.execute(statement)\n",
    "\n",
    "\n",
    "preloaded_imgs_after =  cs.execute (\"\"\"select  img_name\n",
    "from RECOG_DB.ATTEND.embeddings_test\n",
    "order by ID\"\"\").fetchall()\n",
    "\n",
    "\n",
    "preloaded_img_list_after  = [row[0] for row in preloaded_imgs_after ]\n",
    "\n",
    "print(f\"This is the embedings list after. \\n {preloaded_img_list_after}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CODE TO STORE EMBBEDINGS FROM A EMBEDGINGS LIST INTO SNOWFLAKE\n",
    "\n",
    "\n",
    "###for  img_path, embedding in instances:\n",
    "###    # Join embedding values into a comma-separated string\n",
    "###    vec = str(embedding)\n",
    "###    statement = f\"\"\"\n",
    "###        INSERT INTO RECOG_DB.ATTEND.embeddings_test (img_name, embedding)\n",
    "###            SELECT '{img_path}', {vec}::VECTOR(FLOAT,128)\n",
    "###        \"\"\"\n",
    "###    cs.execute(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert sintetic data into the refference databse \n",
    "## in order to check the speed on the search on larger data sets. \n",
    "\n",
    "syn_data = []\n",
    "target_size = 100000\n",
    "for i in range(target_size):\n",
    "    img_name = f\"synthetic_{i}.jpg\"\n",
    "    # generate 128-d embedding with dimension values in [-5, +5]\n",
    "    embedding = np.random.uniform(-5, 5, 128).tolist()\n",
    "    syn_data.append((img_name, embedding))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert sintetic data into the refference databse \n",
    "## in order to check the speed on the search on larger data sets.\n",
    "for  img_path, embedding in syn_data:\n",
    "    # Join embedding values into a comma-separated string\n",
    "    vec = str(embedding)\n",
    "    statement = f\"\"\"\n",
    "        INSERT INTO RECOG_DB.ATTEND.embeddings_test (img_name, embedding)\n",
    "            SELECT '{img_path}', {vec}::VECTOR(FLOAT,128)\n",
    "        \"\"\"\n",
    "    cs.execute(statement)\n",
    "\n",
    "\n",
    "### DONT USE --> TOO SLOW ^\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing with one image on a local directory \n",
    "\n",
    "test_img =  r'C:\\Users\\User\\Pictures\\IMG_3962.png' \n",
    "\n",
    "test_objs = DeepFace.represent(img_path=test_img, model_name=\"Facenet\", anti_spoofing= False)\n",
    "test_embedding = str(test_objs[0][\"embedding\"])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_objs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##comparing the test image with the data base\n",
    "\n",
    "result = cs.execute(f\"\"\"\n",
    "    select  IMG_NAME, VECTOR_L2_DISTANCE(EMBEDDING,{test_embedding}::VECTOR(FLOAT,128)) as SIMILARITY\n",
    "    from RECOG_DB.ATTEND.embeddings_test\n",
    "    ORDER BY SIMILARITY ASC\n",
    "    limit 1\n",
    "\"\"\")\n",
    "\n",
    "bestmacth = result.fetchall()\n",
    "\n",
    "print(bestmacth)\n",
    "\n",
    "str(bestmacth[0][0]).split('/')[-1].split('.')[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition error: Spoof detected in the given image.\n",
      "Recognition error: Spoof detected in the given image.\n",
      "Recognition error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    }
   ],
   "source": [
    "### testing with an vedeo stream from my second monitor\n",
    "\n",
    "\n",
    "\n",
    "# Load Haar cascade for face detection.\n",
    "face_classifier = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# Optionally, precompute your reference embeddings.\n",
    "# For example, you might have a folder \"reference_faces\" with subfolders or images named with the label.\n",
    "# You can run this once at startup to build your embeddings database.\n",
    "# Alternatively, DeepFace.find() can search a folder directly.\n",
    "\n",
    "\n",
    "##db_path = r\"C:\\Users\\User\\Pictures\\Face_recog_db\"\n",
    "\n",
    "def detect_and_recognize(screen_frame):\n",
    "    # Convert frame to grayscale for face detection.\n",
    "    gray_image = cv2.cvtColor(screen_frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray_image, 1.1, 5, minSize=(40, 40))\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract face region of interest (ROI)\n",
    "        face_roi = screen_frame[y:y+h, x:x+w]\n",
    "        # Convert ROI from BGR to RGB (DeepFace expects RGB images)\n",
    "        face_roi_rgb = face_roi ##cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        try:\n",
    "            # Use DeepFace.find() to compare the detected face against your reference database.\n",
    "            # Setting enforce_detection=False to avoid errors if a face isn't perfectly aligned.\n",
    "            \n",
    "            \n",
    "            ##results = DeepFace.find(img_path=face_roi_rgb, db_path=db_path, model_name= \"Facenet\", enforce_detection=False)\n",
    "            results = DeepFace.represent(img_path=face_roi_rgb, model_name=\"Facenet\", anti_spoofing= True)\n",
    "\n",
    "\n",
    "            if len(results) >0 and len(results[0][\"embedding\"]) > 0:\n",
    "\n",
    "                embedding_target = results[0][\"embedding\"] \n",
    "\n",
    "                snow_query_search = f\"\"\"\n",
    "                                        SELECT   IMG_NAME, VECTOR_L2_DISTANCE(EMBEDDING,{embedding_target}::VECTOR(FLOAT,128)) as SIMILARITY\n",
    "                                        FROM RECOG_DB.ATTEND.embeddings_test\n",
    "                                        ORDER BY SIMILARITY ASC\n",
    "                                        LIMIT 1\n",
    "                                    \"\"\"\n",
    "                \n",
    "                \"\"\"insert into RECOG_DB.ATTEND.attendance \n",
    "                \n",
    "                \n",
    "                \"\"\"\n",
    "                \n",
    "                best_match = cs.execute(snow_query_search).fetchall()\n",
    "\n",
    "                label = best_match[0][0].split('/')[-1].split('.')[0]\n",
    "                \n",
    "            else:\n",
    "                label = 'unknown'\n",
    "                \n",
    "            ##if len(results) > 0 and len(results[0]) > 0:\n",
    "            ##    # Assuming results is a list of DataFrames (one per model)\n",
    "            ##    # Get the first match's identity, then extract the name from the file path.\n",
    "            ##    identity_path = results[0].iloc[0][\"identity\"]\n",
    "            ##    label = identity_path.split(\"/\")[-1].split(\"\\\\\")[-1]  # works for Linux/Mac and Windows paths\n",
    "            ##else:\n",
    "            ##    label = \"Unknown\"\n",
    "        except Exception as e:\n",
    "            # If DeepFace fails to process, label as Unknown.\n",
    "            label = \"Unknown_from_exception\"\n",
    "            print(\"Recognition error:\", e)\n",
    "        \n",
    "        # Draw rectangle and label on the frame.\n",
    "        cv2.rectangle(screen_frame, (x, y), (x+w, y+h), (0, 255, 0), 4)\n",
    "        cv2.putText(screen_frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return screen_frame\n",
    "\n",
    "# Capture the screen feed from the second monitor.\n",
    "with mss() as sct:\n",
    "    monitor = sct.monitors[2]\n",
    "    last_sent = 0  # time when the last frame was processed/sent\n",
    "    while True:\n",
    "        # Grab the screen image.\n",
    "        img = np.array(sct.grab(monitor))\n",
    "        # Convert image from BGRA to BGR.\n",
    "        screen_frame = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "        \n",
    "        # Check if 5 seconds have passed since the last processed frame\n",
    "        now = time.time()\n",
    "        if now - last_sent >= 20:\n",
    "            processed_frame = detect_and_recognize(screen_frame)\n",
    "            cv2.imshow(\"My Face Detection & Recognition Project\", processed_frame)\n",
    "            last_sent = now  # update last_sent time\n",
    "\n",
    "        # Even if not sending a frame, check for the 'q' key press to exit.\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n",
      "Recognition error: Face could not be detected in numpy array.Please confirm that the picture is a face photo or consider to set enforce_detection param to False.\n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\User\\Pictures\\juan_esguerra.png'\n",
    "\n",
    "img =cv2.imread(path)\n",
    "img = np.array(img)\n",
    "        # Convert image from BGRA to BGR.\n",
    "screen= cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "\n",
    "processed_frame = detect_and_recognize(screen)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture the screen feed from the second monitor.\n",
    "with mss() as sct:\n",
    "    monitor = sct.monitors[2]\n",
    "    while True:\n",
    "        # Grab the screen image.\n",
    "        img = np.array(sct.grab(monitor))\n",
    "        # Convert image from BGRA to BGR.\n",
    "        screen_frame = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "        \n",
    "        # Detect faces and perform recognition.\n",
    "        processed_frame = detect_and_recognize(screen_frame)\n",
    "        \n",
    "        cv2.imshow(\"My Face Detection & Recognition Project\", processed_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing with an video stream from my second monitor\n",
    "### and attendance insertion table. \n",
    "\n",
    "\n",
    "\n",
    "# Load Haar cascade for face detection.\n",
    "face_classifier = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# Optionally, precompute your reference embeddings.\n",
    "# For example, you might have a folder \"reference_faces\" with subfolders or images named with the label.\n",
    "# You can run this once at startup to build your embeddings database.\n",
    "# Alternatively, DeepFace.find() can search a folder directly.\n",
    "\n",
    "\n",
    "##db_path = r\"C:\\Users\\User\\Pictures\\Face_recog_db\"\n",
    "\n",
    "def detect_and_recognize(screen_frame):\n",
    "    # Convert frame to grayscale for face detection.\n",
    "    gray_image = cv2.cvtColor(screen_frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray_image, 1.1, 5, minSize=(40, 40))\n",
    "\n",
    "    datest =date.today()\n",
    "    formatted_date = datest.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract face region of interest (ROI)\n",
    "        face_roi = screen_frame[y:y+h, x:x+w]\n",
    "        # Convert ROI from BGR to RGB (DeepFace expects RGB images)\n",
    "        face_roi_rgb = face_roi ##cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        try:\n",
    "            # Use DeepFace.find() to compare the detected face against your reference database.\n",
    "            # Setting enforce_detection=False to avoid errors if a face isn't perfectly aligned.\n",
    "            \n",
    "            \n",
    "            ##results = DeepFace.find(img_path=face_roi_rgb, db_path=db_path, model_name= \"Facenet\", enforce_detection=False)\n",
    "            results = DeepFace.represent(img_path=face_roi_rgb, model_name=\"Facenet\", anti_spoofing= True)\n",
    "\n",
    "\n",
    "            if len(results) >0 and len(results[0][\"embedding\"]) > 0:\n",
    "\n",
    "                embedding_target = results[0][\"embedding\"] \n",
    "\n",
    "                snow_query_search = f\"\"\"\n",
    "                                        SELECT   IMG_NAME, VECTOR_L2_DISTANCE(EMBEDDING,{embedding_target}::VECTOR(FLOAT,128)) as SIMILARITY\n",
    "                                        FROM RECOG_DB.ATTEND.embeddings_test\n",
    "                                        ORDER BY SIMILARITY ASC\n",
    "                                        LIMIT 1\n",
    "                                    \"\"\"\n",
    "                \n",
    "                \n",
    "                best_match = cs.execute(snow_query_search).fetchall()\n",
    "\n",
    "                label = best_match[0][0].split('/')[-1].split('.')[0]\n",
    "\n",
    "                attendance_merge = f\"\"\"\n",
    "                MERGE INTO RECOG_DB.ATTEND.attendance_test AS target\n",
    "                USING (\n",
    "                    SELECT '{label}' AS student_name,\n",
    "                           'CAPSTONE_PROJECT' AS class_name,\n",
    "                           '{formatted_date}'::DATE AS attendance_date\n",
    "                ) AS source\n",
    "                ON target.student_name = source.student_name \n",
    "                   AND target.attendance_date = source.attendance_date\n",
    "                WHEN NOT MATCHED THEN\n",
    "                    INSERT (student_name, class_name, attendance_date)\n",
    "                    VALUES (source.student_name, source.class_name, source.attendance_date)\n",
    "                \"\"\"\n",
    "                cs.execute(attendance_merge)\n",
    "                \n",
    "            else:\n",
    "                label = 'unknown'\n",
    "                \n",
    "\n",
    "        except Exception as e:\n",
    "            # If DeepFace fails to process, label as Unknown.\n",
    "            label = \"Unknown_from_exception\"\n",
    "            print(\"Recognition error:\", e)\n",
    "        \n",
    "        # Draw rectangle and label on the frame.\n",
    "        cv2.rectangle(screen_frame, (x, y), (x+w, y+h), (0, 255, 0), 4)\n",
    "        cv2.putText(screen_frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return screen_frame\n",
    "\n",
    "# Capture the screen feed from the second monitor.\n",
    "with mss() as sct:\n",
    "    monitor = sct.monitors[2]\n",
    "    last_sent = 0  # time when the last frame was processed/sent\n",
    "    while True:\n",
    "        # Grab the screen image.\n",
    "        img = np.array(sct.grab(monitor))\n",
    "        # Convert image from BGRA to BGR.\n",
    "        screen_frame = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)\n",
    "        \n",
    "        # Check if 5 seconds have passed since the last processed frame\n",
    "        now = time.time()\n",
    "        if now - last_sent >= 20:\n",
    "            processed_frame = detect_and_recognize(screen_frame)\n",
    "            cv2.imshow(\"My Face Detection & Recognition Project\", processed_frame)\n",
    "            last_sent = now  # update last_sent time\n",
    "\n",
    "        # Even if not sending a frame, check for the 'q' key press to exit.\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-05\n"
     ]
    }
   ],
   "source": [
    "datest =date.today()\n",
    "formatted_date = datest.strftime(\"%Y-%m-%d\")\n",
    "print(formatted_date) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from botocore.exceptions import ClientError\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "import snowflake.connector as sc\n",
    "\n",
    "\n",
    "\n",
    "def get_secret():\n",
    "    secret_name = \"snowflake/face_rec/rsa_private_key\"\n",
    "    region_name = \"us-east-2\"\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    return secret\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_private_key(pem_str, key_password=None):\n",
    "    \"\"\"\n",
    "    Load a PKCS8 formatted private key from a PEM string.\n",
    "    key_password should be a string if the key is encrypted, otherwise None.\n",
    "    \"\"\"\n",
    "    private_key = serialization.load_pem_private_key(\n",
    "        pem_str.encode(\"utf-8\"),\n",
    "        password=key_password.encode(\"utf-8\") if key_password else None,\n",
    "        backend=default_backend()\n",
    "    )\n",
    "    return private_key\n",
    "\n",
    "# Retrieve the private key string from AWS Secrets Manager.\n",
    "pem_private_key = get_secret()\n",
    "\n",
    "print(type(pem_private_key))\n",
    "\n",
    "\n",
    "##first_value = next(iter(pem_private_key.values()))\n",
    "##print(first_value)\n",
    "\n",
    "# If your key is not encrypted, key_password is None.\n",
    "key_password = None  # Set this if your private key is password-protected\n",
    "\n",
    "\n",
    "\n",
    "##fixed_private_key = fix_pem_format(first_value)\n",
    "\n",
    "# Load the private key into a cryptography object.\n",
    "private_key = load_private_key(pem_private_key, key_password=key_password)\n",
    "\n",
    "##private_key = r\"D:\\Users\\Andrsfch\\Documents\\Snowflake Configs\\rsa_key.p8\"\n",
    "\n",
    "# Snowflake connection parameters using key-pair authentication.\n",
    "conn_params = {\n",
    "    'account': 'TIMCEXC-MYB81917',\n",
    "    'user': 'face_rec_service',\n",
    "    'private_key': private_key,\n",
    "    'warehouse': 'COMPUTE_WH',\n",
    "    'database': 'RECOG_DB',\n",
    "    'schema': 'ATTEND'\n",
    "}\n",
    "\n",
    "# Connect to Snowflake.\n",
    "ctx = sc.connect(**conn_params)\n",
    "cs = ctx.cursor()\n",
    "\n",
    "# Example query.\n",
    "cs.execute(\"SELECT *  FROM RECOG_DB.ATTEND.institution\")\n",
    "print(cs.fetchone())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from cryptography.hazmat.primitives import serialization\n",
    "from cryptography.hazmat.backends import default_backend\n",
    "\n",
    "def fix_pem_format(pem_str):\n",
    "    \"\"\"\n",
    "    Reformat a PEM string to ensure proper line breaks.\n",
    "    This assumes that the key is in the format:\n",
    "    \"-----BEGIN PRIVATE KEY----- <base64 data> -----END PRIVATE KEY-----\"\n",
    "    and rewraps the base64 data at 64-character intervals.\n",
    "    \"\"\"\n",
    "    header = \"-----BEGIN PRIVATE KEY-----\"\n",
    "    footer = \"-----END PRIVATE KEY-----\"\n",
    "    \n",
    "    # Remove any extra whitespace at the ends.\n",
    "    pem_str = pem_str.strip()\n",
    "    \n",
    "    if header in pem_str and footer in pem_str:\n",
    "        # Split by header and footer\n",
    "        start = pem_str.find(header) + len(header)\n",
    "        end = pem_str.find(footer)\n",
    "        # Remove spaces from the middle section\n",
    "        base64_data = pem_str[start:end].strip().replace(\" \", \"\")\n",
    "        # Rewrap the base64 content to 64-character lines\n",
    "        wrapped = \"\\n\".join(textwrap.wrap(base64_data, 64))\n",
    "        fixed_pem = f\"{header}\\n{wrapped}\\n{footer}\"\n",
    "        return fixed_pem\n",
    "    else:\n",
    "        # If header/footer not found, return as-is\n",
    "        return pem_str\n",
    "\n",
    "# Assume pem_private_key_str is the key string retrieved from Secrets Manager.\n",
    "pem_private_key_str = \"\"\"\n",
    "-----BEGIN PRIVATE KEY-----\n",
    "MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDdb/MYUexc/8su\n",
    "5Oak6Intul91OxsWz4EDQ59MTNaTi0cdMLcX07qNKyylK8J3jze9Sqzz1qfiprv4\n",
    "ZxeGahFQV0mdB8uKuklA7Sit5H9yLAxU/gCmsWf1Y6bPF3IK/+x57sws5YwOS2ME\n",
    "i9ofRUxP357jWHPVGUmMHL54s4HKZE8dF1Vp7xdtDXSErcH0pht1N4OvPQgP+fLL\n",
    "OruEJWtSvUUsyf9Bp+RZd2sH80aQNFrkhsBMCqibIqXv1uohkM7+pG+eHrBzw6W2\n",
    "jSikuF0TeSFao+6mAXPZ1bZtzeSDjfxumvu+W7tzhEHmCZ6FhDGxT2bN8BwwQr9H\n",
    "Vb+zslsNAgMBAAECggEAK+kD693s8LkhjaRC708UcNF9FeZZVhHiS6coas0u3LWo\n",
    "7asoF3+7FbzKvtsZVjOOckkhWD4H7xwwmI663cLhOY0BkjPGQzVzCr6siyUNN7Lv\n",
    "5Be1QdjanFC9NoI38WHz/u7hSoLfXcNJuJBR+dL4UbtuircSyx5XVQMrKwyvj1Yr\n",
    "saj3b9k9MG9uDK51XURlT80WmfEq+lSRaCiuBQKReuC4nlky5yxmib8buU/u+G7I\n",
    "9o1oGs43fEMQnzTiLyGzEoItTxPaQHQYSvqFMHJVauLUxfbvKsTqTXHNuI9xJBAT\n",
    "PIDCrJYTxC8Q6DgG5gBtImk2ujDjJrjKl+Zl0Sx/gQKBgQD96APiOgT0lWMmsVdY\n",
    "PhXiBup2bKgRWKvnN95K46+NtztdZxcCOuf0DQ8TZLqW439GLdyYE5a36xPkzoUJ\n",
    "nC7oQPvhOPYRohOtvuh+yXd5uD4D1GbtSnzmcWnVBtL8xk/R8XbDWt6YcgNUtfID\n",
    "6LX0FrLwtoRUTsN1JSS1V589gQKBgQDfQ2TQT8xo8mTkDku18BuvW8Q03mYK+y0O\n",
    "E+xbAPFyKWTAVD4vQ/89yRfFJj/do64nZ+qkjgmhUmdkJtIS3ufajZasYaix9dKk\n",
    "ts21HCpSKZSLZKrkZXWH2caYScI7nw9iqcdmtVUIcmK7QXpHEIyP9TBi5Z2K/WgU\n",
    "CDgMh7D7jQKBgHkd2exqPL7nG9rzMXUYeJvPLLy87BcKM0YicllK7w0s4JaXfHRF\n",
    "4SubpxtbK16aurWhXt70SSsGagD1OqTw6bdEeGJhJ5AVvkldDc6dD+7yIjL1ePus\n",
    "UpQieZdyn+aQOrcs9bgOeqxBhrE78WxH77O1uDn29ny47afNxgry9zUBAoGBAMTz\n",
    "Obq9uk+WDMRVjBpaTsHZzPLqgdAMFYnGr4j0Awo3U8aKSjT94erKO2rSPCK0Ioxm\n",
    "kkpJdltWSxjBWi4FbziQEKvOlrcuaHyfOkYbK4ZBYeW5jztd+Vk3Fob/AhYAUd0y\n",
    "clG7guCpr0kLEOghxC22GNIVRm3271pEidUb2ld9AoGBAIx8dL6eumLy4a34h3/t\n",
    "ic1Gy6FhHkBwBBSSMqoNKqae+3fASNBaT+z+ZCoZQ6Nf+ORw+Fpeeu8K1NB3+U39\n",
    "hrgyvhyWPnOED4hs5bgJEYU+AZFJ1QRN7JxzkjMWJps+XYmNLqm0xWIOLDSs+2jN\n",
    "S7us6arqgRM76oXJ1paLsmhW\n",
    "-----END PRIVATE KEY-----\n",
    "\n",
    "\"\"\"\n",
    "# Fix the PEM formatting:\n",
    "fixed_pem = fix_pem_format(pem_private_key_str)\n",
    "print(repr(fixed_pem))\n",
    "\n",
    "# Now try loading the key:\n",
    "try:\n",
    "    private_key = serialization.load_pem_private_key(\n",
    "        fixed_pem.encode(\"utf-8\"),\n",
    "        password=None,  # or provide your key password if needed\n",
    "        backend=default_backend()\n",
    "    )\n",
    "    print(\"Private key loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load private key:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a session with your AWS access keys and region\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id='AKIATG6MGZ27MEZI7EM3',\n",
    "    aws_secret_access_key='NjwfpnIGoKqZYNneFLd6MxRc9QMc15w8YXi5jD3a',\n",
    "    region_name='us-east-2'  # Change to your desired region\n",
    ")\n",
    "\n",
    "# Create a client for Secrets Manager (or any other service)\n",
    "client = session.client('secretsmanager')\n",
    "\n",
    "# Example: List secrets to verify the connection\n",
    "response = client.list_secrets()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
